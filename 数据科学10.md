# Lecture 10

## Coding - ode45

### 在ode45中输入函数的两种方法

#### 1.内敛函数

```matlab
[t,y] = ode45(@(t,y) A*y,[0,T],y0);
```

#### 2.显式函数
```matlab
function dy = odefun(t,y,d,w)

A = [0 1;-w^2 -2*d*w];
dy = A * y;
```

或者每一个分量分别表示：

```matlab
function dy = odefun(t,y,d,w)

dy(1,1)=y(2);
...
```

在调用ode45时，记得加上@以识别：

```matlab
[t,y] = ode45(@odefun,[0,T],y0);
```

> 当函数的参数量大于结果向量参数个数时，使用内敛函数：
> ```matlab
> [t,y] = ode45(@(t,y) odefun(t,y,d,w),[0,T],y0);
> ```

## Optimization（优化）

#### What to optimize?->'objective function' $f(x),x\in R^n$
$\min\limits_{x} f(x)$
在这个问题中，x没有约束，即$x:x\in R^n$，称为**无约束问题（unconstrained problem）**
**约束问题（constrained problem）**：$x:x\in C\subseteq R^n$，表达为
$\min\limits_{x\in C} f(x),or\begin{cases}\min\limits_{x} f(x) \\ s.t. \, g_i(x)\leq 0 & i=1,..,m \\ h_j(x)=0 & j=1,..,p\end{cases}$
#### 'minimization'
find $x^*$ such that $f(x)\geq f(x^*)$ for any $x\in R^n/C$

$x^*$:**optimal variable**

$f(x^*)$:**optimal value**

### Outline
* Gradient-free methods($\min\limits_{x\in R} f(x)$)
* Gradient methods(first-order methods)
> Deep Learning:一阶方法
* Newton's method(second-order methods)
> Qusi-Newton:减少计算量
* Application:curve fitting
* Application:linear model
* (Matrix Differtiation)